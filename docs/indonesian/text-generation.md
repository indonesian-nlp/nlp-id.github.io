# Text Generation

## Models

| Name                                                       | Description                                                                                                                                                                                          | Author                 | Link                                                                                     |
|------------------------------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|------------------------|------------------------------------------------------------------------------------------|
| Indonesian GPT2 Small 522M                                 | It is GPT2-small model pre-trained with indonesian Wikipedia using a causal language modeling (CLM) objective. This model is uncased: it does not make a difference between indonesia and Indonesia. | Cahya Wirawan          | [HuggingFace](https://huggingface.co/cahya/gpt2-small-indonesian-522M)                   |
| GPT2-small-indonesian                                      | This is a pretrained model on Indonesian language using a causal language modeling (CLM) objective. The training data used for this model are Indonesian websites of OSCAR, mc4 and Wikipedia.       | Flax Community         | [HuggingFace](https://huggingface.co/flax-community/gpt2-small-indonesian)               |
| GPT2-medium-indonesian                                     | This is a pretrained model on Indonesian language using a causal language modeling (CLM) objective. The training data used for this model are Indonesian websites of OSCAR, mc4 and Wikipedia.       | Flax Community         | [HuggingFace](https://huggingface.co/flax-community/gpt2-medium-indonesian)              |
| Indonesian GPT-2 finetuned on Indonesian academic journals | This is the Indonesian gpt2-small model fine-tuned to abstracts of Indonesian academic journals. All training was done on a TPUv2-8 VM sponsored by TPU Research Cloud.                              | Galuh                  | [HuggingFace](https://huggingface.co/Galuh/id-journal-gpt2)                              |
| Indonesian GPT-2-medium finetuned on Indonesian poems      | This is the Indonesian gpt2-medium model fine-tuned to Indonesian poems.                                                                                                                             | Muhammad Agung Hambali | [HuggingFace](https://huggingface.co/ayameRushia/gpt2-medium-fine-tuning-indonesia-poem) |
| Indonesian GPT-2 finetuned on Indonesian poems             | This is the Indonesian gpt2-small model fine-tuned to Indonesian poems.                                                                                                                              | Muhammad Agung Hambali | [HuggingFace](https://huggingface.co/ayameRushia/gpt2-small-indonesia-fine-tuning-poem)  |
| Indo GPT-2 Small                                           | Indo GPT-2 Small is a language model based on the GPT-2 model. It was trained on the latest (late December 2020) Indonesian Wikipedia articles.                                                      | Wilson Wongso          | [HuggingFace](https://huggingface.co/w11wo/indo-gpt2-small)                              |
